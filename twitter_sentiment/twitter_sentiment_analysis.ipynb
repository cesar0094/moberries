{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n",
    "Create a Jupyter notebook with a simple analysis based on Twitter Sentiment Analysis Training Corpus:\n",
    "http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us load the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/cesar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/cesar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Bidirectional, Input, LSTM, Dense, Dropout, Activation, Conv1D, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "seed = 1\n",
    "tf.set_random_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the [dataset](http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip) has not been downloaded, run the cell below to do so. Otherwise, copy it to the project folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = \"http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip\"\n",
    "download_path = os.path.join(\".\", \"Sentiment-Analysis-Dataset.zip\")\n",
    "\n",
    "urllib.request.urlretrieve(download_url, download_path)\n",
    "with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"Sentiment Analysis Dataset.csv\", error_bad_lines=False)\n",
    "print(\"Number of lines loaded:\", len(df))\n",
    "print(\"Positive tweets:\", len(df[df.Sentiment == 1]))\n",
    "print(\"Negative tweets:\", len(df[df.Sentiment == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Before performing the tasks, we need to preprocess the data, removing undesired characters and words (such as links) and tokenizing the clean tweets into arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanitizing step. Remove handles, links, and non-alpha (except for '?', '!' and '#') characters\n",
    "# Note: this could be done in one step with the regex option | but we leave it for readability.\n",
    "clean_tweets = df.SentimentText.str.lower().str.replace(\"@[A-Za-z0-9_]+\", \"\")\n",
    "clean_tweets = clean_tweets.str.replace(\"http?://[^ ]+\", \"\")\n",
    "clean_tweets = clean_tweets.str.replace(\"https?://[^ ]+\", \"\")\n",
    "clean_tweets = clean_tweets.str.replace(\"www.[^ ]+\", \"\")\n",
    "clean_tweets = clean_tweets.str.replace(\"[^a-z ?!#]\", \"\")\n",
    "\n",
    "df['CleanTweet'] = clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the tweet tokenizer provided by NLTK, apart from normal tokenization,\n",
    "# it helps us reduce the length of words like: wooooowwwwwww to wooowww \n",
    "# so there is less vocabulary without stripping much context.\n",
    "tt = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "tokenized_tweets = df.CleanTweet.apply(tt.tokenize)\n",
    "\n",
    "def lemmatize(sentence):\n",
    "    return [lemmatizer.lemmatize(w) for w in sentence]\n",
    "\n",
    "# And finally a lemmatizing step.\n",
    "lemmatized_tweets = tokenized_tweets.apply(lemmatize)\n",
    "df['TokenizedTweet'] = lemmatized_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can take a look at a few sanitized examples\n",
    "print(lemmatized_tweets.sample(5).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After lemmatizing and removing non-alpha digits, we are ready to analyze the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Show the top-10 most positive words, top-10 negative words (words more frequent with positive and negative labels respectively).\n",
    "\n",
    "We present two approaches to find this: \n",
    "* The first is by calculating the difference between positive and negative tweets a word appears in (and vice-versa for negative sentiment) and presenting the highest scores. This calculation favors words with more frequency thus stop words like \"i\", \"but\" and \"the\" may appear. \n",
    "* The second approach is to calculate the ratio of positive to negative tweets a word appears in and present the top 10. This list may contain words that, even though are not very common, people used them more on a certain context than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "negative_words = defaultdict(int)\n",
    "positive_words = defaultdict(int)\n",
    "\n",
    "# let's count how many positive/negative appearances each word has\n",
    "def count_negative(sentence):\n",
    "    for w in sentence: negative_words[w]+=1\n",
    "\n",
    "def count_positive(sentence):\n",
    "    for w in sentence: positive_words[w]+=1\n",
    "\n",
    "df[df.Sentiment == 1].TokenizedTweet.apply(count_positive)\n",
    "df[df.Sentiment == 0].TokenizedTweet.apply(count_negative)\n",
    "\n",
    "word_to_sentiment = DataFrame({\n",
    "    'NegativeCount' : Series(negative_words),\n",
    "    'PositiveCount' : Series(positive_words),\n",
    "})\n",
    "\n",
    "word_to_sentiment['TotalCount'] = word_to_sentiment.NegativeCount + word_to_sentiment.PositiveCount\n",
    "print(\"Top 10 positive words by difference\")\n",
    "print((word_to_sentiment.PositiveCount - word_to_sentiment.NegativeCount).nlargest(10))\n",
    "print()\n",
    "print(\"Top 10 negative words by difference\")\n",
    "print((word_to_sentiment.NegativeCount - word_to_sentiment.PositiveCount).nlargest(10))\n",
    "print()\n",
    "print(\"Top 10 positive words by ratio\")\n",
    "print((word_to_sentiment.PositiveCount / word_to_sentiment.TotalCount).nlargest(10))\n",
    "print()\n",
    "print(\"Top 10 negative words by ratio\")\n",
    "print((word_to_sentiment.NegativeCount / word_to_sentiment.TotalCount).nlargest(10))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "Check the Zipf law (https://en.wikipedia.org/wiki/Zipf%27s_law: the frequency of any word is inversely proportional to its rank in the frequency table), show it using a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = word_to_sentiment.TotalCount.sort_values(ascending=False)\n",
    "\n",
    "y = np.array(sorted_words, dtype=pandas.Series)\n",
    "x = np.array(range(len(y)))\n",
    "\n",
    "# a very rough estimate of Zipf's law, just to illustrate its trend\n",
    "zipfs = 1./(x+0.000001)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, label='dataset')\n",
    "ax.plot(x, zipfs, label=\"Zipf's law\")\n",
    "\n",
    "ax.set_title(\"Rank vs. Frequency and Zipf's law\")\n",
    "ax.set_xlabel('rank')\n",
    "ax.set_ylabel('frequency')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Write a simple classifier to predict sentiment, describe your approach and what can be done to improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good choice for a sentiment classifier is a bidirectional RNN with word embeddings as inputs. There are several reasons to choose such a model:\n",
    "* The overall sentiment is dependent on the whole sequence, and an RNN is capable of considering relationships across inputs, in this case, word embeddings.\n",
    "* A bidirectional RNN allows us to look at the dependencies not only from beginning to end but also from end to beginning. A negative word at the end can change the whole context of the tweet. Example: I love rain. NOT!\n",
    "* Word embeddings capture different features of a word, usually representing their occurrences with other words. Similar words have similar word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to obtain our embeddings matrix. We could download a set of pre-trained embeddings but using our own we make sure that the embeddings weights match our dataset domain. If we use pre-trained embeddings, the word embeddings will be with respect to the corpus it was trained on, which may or may not transfer well to our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_len = 100\n",
    "word2vec = Word2Vec(sentences=df.TokenizedTweet, size=embedding_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a few examples of our word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer = [w for w, s in word2vec.wv.most_similar('computer')]\n",
    "angry = [w for w, s in word2vec.wv.most_similar('angry')]\n",
    "print(\"Words similar to computer:\\n\", computer)\n",
    "print(\"Words similar to angry:\\n\", angry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Keras Tokenizer which helps us with the input format of the embedding layer\n",
    "filters = '\"$%&()*+,-./:;<=>[\\]^_`{|}~'\n",
    "vocabulary_len = 100000\n",
    "tokenizer = Tokenizer(filters=filters, num_words=vocabulary_len)\n",
    "tokenizer.fit_on_texts(df.TokenizedTweet)\n",
    "max_words_in_tweet = max(df.TokenizedTweet.apply(len))\n",
    "print(\"Max number of words in a tweet:\" , max_words_in_tweet)\n",
    "\n",
    "# building the embeddings for the vocabulary we use\n",
    "embeddings = np.zeros((vocabulary_len, embedding_len))    \n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if word in word2vec.wv:\n",
    "        embeddings[index, :] = word2vec.wv[word]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our huge dataset of >1.5M samples, we can afford to have a bigger training set with smaller validation and test sets. We do a 98-1-1 split and prepare the sets in the correct input format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, rest_df = train_test_split(df, train_size=0.98)\n",
    "val_df, test_df = train_test_split(rest_df, train_size=0.5) # ~40k each\n",
    "\n",
    "# To use the Embedding layer we need to represent words in sentences by their index in the dict.\n",
    "# The inputs need to be transformed to be vectors of indices in the dict for each word.\n",
    "X_train = tokenizer.texts_to_sequences(train_df.TokenizedTweet)\n",
    "# The inputs have to be of the same dimensions, regardless of the numbers of words in a sentence.\n",
    "X_train = pad_sequences(X_train, maxlen = max_words_in_tweet, padding=\"post\")\n",
    "Y_train = train_df.Sentiment.to_numpy()\n",
    "\n",
    "X_val = tokenizer.texts_to_sequences(val_df.TokenizedTweet)\n",
    "X_val = pad_sequences(X_val, maxlen=max_words_in_tweet, padding=\"post\")\n",
    "Y_val = val_df.Sentiment.to_numpy()\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test_df.TokenizedTweet)\n",
    "X_test = pad_sequences(X_test, maxlen=max_words_in_tweet, padding=\"post\")\n",
    "Y_test = test_df.Sentiment.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set size:\", len(train_df))\n",
    "print(\"Validation set size:\", len(val_df))\n",
    "print(\"Test set size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM-based RNN with a single sigmoid activation output\n",
    "def TweetSentimentRNNModel(lstm_units, input_size, embeddings):\n",
    "    inputs = Input(shape=(input_size,), dtype='int32')\n",
    "\n",
    "    # The Embedding layer will be in charge of converting our sentences with indices to word embeddings.\n",
    "    # Since we have to pre-trained word embeddings, we allow the optimizer to train its parameters.\n",
    "    vocabulary_len, embedding_size = embeddings.shape\n",
    "    embedding_layer = Embedding(vocabulary_len, embedding_size, weights=[embeddings], input_length=input_size, trainable=False)\n",
    "    \n",
    "    X = embedding_layer(inputs)\n",
    "    # After converting to word embeddings, we pass them to the bidirectional LSTM.\n",
    "    X = Bidirectional(LSTM(lstm_units))(X)\n",
    "    # The encoding produced by the LSTM is passed to an output node using sigmoid activation.\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preparing the inputs and declaring our model, we proceed to train our model and find the best number of LSTM units to use. We could perform cross-validation and different iterations to reduce overfitting. In this case, only one loop over the range of LSTM units and we keep the validation set static. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test different number of units for the LSTM to find the best number that can be used\n",
    "models = {\n",
    "    8: TweetSentimentRNNModel(8, max_words_in_tweet, embeddings), \n",
    "    16: TweetSentimentRNNModel(16, max_words_in_tweet, embeddings), \n",
    "    32: TweetSentimentRNNModel(32, max_words_in_tweet, embeddings), \n",
    "    64: TweetSentimentRNNModel(64, max_words_in_tweet, embeddings), \n",
    "    128: TweetSentimentRNNModel(128, max_words_in_tweet, embeddings), \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The training time is very long, you can load the trained weights in the cell below this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lstm_units, model in models.items():\n",
    "    \n",
    "    # Save the models best validation accuracy weights\n",
    "    filepath = \"models/LSTM_{}_pretrained_embeddings_\".format(lstm_units) + \"best_weights_{epoch:02d}_epochs.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    # We use early stop of 1 because the model converges quickly given the huge dataset. \n",
    "    # The accuracy and loss do not improve further.\n",
    "    early_stop = EarlyStopping(monitor='val_acc', patience=1, min_delta=0.001, mode='max') \n",
    " \n",
    "    # We choose adam optimizer which uses both momentum and RMSprop for faster learning.\n",
    "    adam = Adam(lr=0.01)\n",
    "    # Since we are dealing with a binary classification problem, we minimize the binary log loss or cross-entropy\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    \n",
    "    print(\"Training with lstm_units:\", lstm_units)\n",
    "    model.fit(X_train, Y_train, \n",
    "              validation_data=(X_val, Y_val), \n",
    "              callbacks=[early_stop, checkpoint], \n",
    "              batch_size=250,\n",
    "              epochs=50, \n",
    "              shuffle=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_filepath = {\n",
    "    8: \"models/LSTM_8_pretrained_embeddings_best_weights_01_epochs.hdf5\", \n",
    "    16: \"models/LSTM_16_pretrained_embeddings_best_weights_01_epochs.hdf5\", \n",
    "    32: \"models/LSTM_32_pretrained_embeddings_best_weights_03_epochs.hdf5\", \n",
    "    64: \"models/LSTM_64_pretrained_embeddings_best_weights_01_epochs.hdf5\", \n",
    "    128: \"models/LSTM_128_pretrained_embeddings_best_weights_01_epochs.hdf5\", \n",
    "}\n",
    "for lstm_units, filepath in models_filepath.items():\n",
    "    model = models[lstm_units]\n",
    "    model.load_weights(filepath, by_name=False)\n",
    "    adam = Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    print(\"%s LSTM units\" % lstm_units)\n",
    "    loss, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    print(\"Validation accuracy = %0.4f\" % acc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best validation accuracy was `80.51%` with `32` LSTM units, nevertheless the rest of the models had similar scores. We could follow Occam's Razor and choose the simpler model with `8` units since it may be less prone to overfit and way faster to train and evaluate without sacrificing much accuracy but let's keep the `32` units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use a completely separate dataset from training and validation sets to provide a final accuracy for our model since we trained by optimizing their results. We use our test set for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = best_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Test accuracy = %0.4f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the low training accuracies, the model was not able to fit the training data completely. This could be due to the embeddings we are using. We can verify this with a model with trainable embeddings. Note that having trainable embeddings increases the training time considerably due to the increase in the number of parameters. By sacrificing some training speed, we hope the model will learn which embedding weights are more useful to predict sentiment, so the training accuracy can be higher and hopefully, this translates into a higher validation/test accuracy. Because the training is very slow, we choose 8 LSTM units for this model but keep the embedding size of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TweetSentimentTrainableEmbeddingsModel(lstm_units, input_size, vocab_len, embedding_size):\n",
    "    inputs = Input(shape=(input_size,), dtype='int32')\n",
    "    \n",
    "    X = Embedding(vocab_len, embedding_size, trainable=True)(inputs)\n",
    "    X = Bidirectional(LSTM(lstm_units))(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 8\n",
    "model = TweetSentimentTrainableEmbeddingsModel(lstm_units, max_words_in_tweet, vocabulary_len, embedding_size=100)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the training of this model is much slower, we choose the number of LSTM units based on our previous results to get a quick result, although this does not mean it is the best number of LSTM units for this model as well.\n",
    "\n",
    "**Note:** The training time is very long, you can load the trained weights in the cell below this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"models/LSTM_{}_trainable_embeddings_\".format(lstm_units) + \"best_weights_{epoch:02d}_epochs.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=1, min_delta=0.001, mode='max') \n",
    "\n",
    "model.fit(X_train, Y_train, \n",
    "          validation_data=(X_val, Y_val), \n",
    "          callbacks=[early_stop, checkpoint], \n",
    "          epochs=50, \n",
    "          batch_size=250, \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"models/LSTM_8_trainable_embeddings_best_weights_02_epochs.hdf5\"\n",
    "model.load_weights(filepath, by_name=False)\n",
    "loss, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"Validation accuracy = %0.4f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Test accuracy = %0.4f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 8 LSTM units and allowing the embedding layer to be trainable, we obtained a validation accuracy of `82.09%` and a similar test accuracy of `82.18%`, meaning the model generalized well. There is a small increase in accuracy of `~3%` compared to the pretrained embeddings with 8 LSTM units. This indicates that the pretrained embedding layer was holding the model back on fitting the data, thus it could be an area of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentative Improvements\n",
    "The model used for sentiment prediction was a simple LSTM-based RNN and it used word embeddings both pre-trained and trainable. We saw that allowing embeddings to be trainable increased the accuracy of the model, but it came with a high increase in training time due to the number of parameters. Considering the improvement was around 3%, it may be worth exploring more complex or deeper models as well as looking into the data preprocessing step for improvements. \n",
    "\n",
    "While the selection of a model is important, also the preprocessing of data can affect the performance. If our preprocessing step ends up removing too many pieces, the context required by the model won't be there. On the other hand, if we don't sanitize our data enough, the model might not be able to generalize from the training data to the testing data. This preprocessing step along with the vocabulary size can also be tweaked to explore other results.\n",
    "\n",
    "Making use of publicly available word embeddings is also a possibility, although given that the dataset has a very particular use of words, it would be surprising if they produce improvements.\n",
    "\n",
    "Adding more layers to our RNN may help us fit our dataset better. These layers can be other than LSTM, for example after the encoding step of the LSTM, we can have one or more fully-connected layers before reaching the output node. Another approach to consider is the attention model, which is widely used in machine translation due to its performance with longer sequences.\n",
    "\n",
    "Other models that can be used are CNNs, which are usually used for image classification and analysis but have had attention on sequence analysis as well. Their convolution steps allow them to identify and group low-level patterns into higher-level patterns. In our case, it can go from character-level information to sentence-level patterns. Nogueira et al. obtained an accuracy of 86.4\\% using such architecture (https://www.aclweb.org/anthology/C14-1008), so we can see that the dataset is hard to fit even by more intricate models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
